""" QIP Cube â€“ Minimal Runnable Skeleton (v0.1) Author: Mirko & GPT-5 Thinking License: MIT

Purpose

A compact, dependency-free Python skeleton that implements the key ideas from the "QIP Cube â€“ Architektura moduÅ‚Ã³w i autokonfiguracja v0.1" draft:

Signal normalization â†’ SPI inference â†’ Policy selection â†’ Module execution â†’ Evaluation â†’ Learning (bandit) â†’ Deep save

Pluggable Modules: Analytic, Therapeutic, Creative, Strategic, Experimental

Metrics mix, fast/deep modes, hysteresis switching, explainability

JSON-de/serializable state for portability


How to run

Save this file as qip_cube.py

Run: python qip_cube.py

Inspect the printed demo loop and the produced deep_state.json


Notes

All metrics are operational placeholders (simple heuristics). Replace with your real QIP metrics as they mature.

Safety: TherapeuticCube includes a basic guardrail channel; extend with your protocol.

Bandit: Epsilon-greedy contextual bandit with per-module value estimates keyed by coarse SPI bins.

Hysteresis: windowed stability check before switching primary module. """ from future import annotations


import json import math import random import statistics from collections import deque from dataclasses import dataclass, asdict, field from typing import Any, Dict, List, Optional, Tuple

-----------------------------

1) Data structures

-----------------------------

@dataclass class LexicalStats: length: int punct_var: float  # 0..1 rough punctuation variance

@dataclass class AffectGuess: valence: float  # -1..1 internal, mapped to 0..1 externally arousal: float  # 0..1 certainty: float  # 0..1

@dataclass class SignalPacket: text_raw: str lang: str = "pl" timestamp: Optional[str] = None session_id: Optional[str] = None lexical_stats: Optional[LexicalStats] = None affect_guess: Optional[AffectGuess] = None intent_hint: Optional[str] = None  # pytanie/proÅ›ba/wyrzut/eksploracja risk_flags: Optional[List[str]] = None  # kryzys/autoagresja/uzaleÅ¼nienie context_refs: Optional[List[str]] = None  # projekty, bramy, rytuaÅ‚y

@dataclass class SPI: dominant_mode: str  # analityczny/intuicyjny/emocjonalny/somatyczny/hybryda paradox_tolerance: float emergence_readiness: float shadow_integration: float authenticity_index: float

@dataclass class Metrics: T_index: float = 0.0 psi_charge: float = 0.0 semantic_c: float = 0.0 entanglement: float = 0.0 LOF: float = 0.0 Token_ROI: float = 0.0 GVI: float = 0.0 PLS: float = 0.0 ACF: float = 0.0 paradox_tolerance: float = 0.0 emergence_readiness: float = 0.0 shadow_integration: float = 0.0 authenticity_index: float = 0.0 TDEX: float = 0.0 SDX: float = 0.0

def mix(self, weights: Dict[str, float]) -> float:
    return sum(getattr(self, k, 0.0) * w for k, w in weights.items())

# â€”â€” QIP-aligned non-linear couplings (DeepSeek hotfix) â€”â€”
def calculate_qip_aligned(self) -> None:
    # T_index: sigmoid over coupled drivers
    self.T_index = 1.0 / (1.0 + math.exp(-2.0 * (
        0.7 * self.psi_charge +
        0.5 * math.log(0.1 + max(self.entanglement, 0.0)) -
        0.3 * (1.0 - self.ACF)
    )))
    # TDEX: exponential sensitivity to entanglement and semantic propagation
    self.TDEX = math.exp(self.entanglement) * (self.semantic_c / 100.0) * math.sqrt(max(0.0, abs(self.T_index - 0.5)))
    # LOF: resonance between coherence and potential
    self.LOF = math.sin(math.pi * clamp(self.ACF)) * (1.0 + 0.3 * math.cos(2.0 * math.pi * clamp(self.psi_charge)))

@dataclass class ModuleResult: text: str artifacts: List[str] metrics: Metrics why: str  # explainability: why this module and what it did

-----------------------------

2) Utility â€“ normalization & heuristics

-----------------------------

def clamp(x: float, lo: float = 0.0, hi: float = 1.0) -> float: return max(lo, min(hi, x))

def normalize_packet(packet: SignalPacket) -> SignalPacket: # Auto-fill simple lexical stats if packet.lexical_stats is None: length = len(packet.text_raw) punct = sum(1 for ch in packet.text_raw if ch in ",.;:!?â€¦â€”-()[]{}" ) punct_var = clamp((punct / max(1, length)) * 5.0)  # rough proxy packet.lexical_stats = LexicalStats(length=length, punct_var=punct_var) # Naive affect if missing if packet.affect_guess is None: valence = clamp((packet.text_raw.count(":)") - packet.text_raw.count(":(")) * 0.2 + 0.5) arousal = clamp(min(1.0, 0.2 + len(packet.text_raw) / 400.0)) certainty = clamp(0.6 - packet.text_raw.count("?") * 0.1) packet.affect_guess = AffectGuess(valence=valence*2-1, arousal=arousal, certainty=certainty) return packet

def infer_spi(packet: SignalPacket) -> SPI: # Very rough, replace with your true SPI model emo_weight = clamp(0.6 * (1 - packet.affect_guess.certainty) + 0.4 * packet.affect_guess.arousal) dominant_mode = ( "emocjonalny" if emo_weight > 0.55 else "analityczny" if packet.lexical_stats.length > 220 and packet.affect_guess.certainty > 0.5 else "intuicyjny" ) paradox_tolerance = clamp(0.3 + packet.text_raw.count("paradoks") * 0.2) emergence_readiness = clamp(0.4 + 0.3 * (1 - packet.affect_guess.certainty)) shadow_integration = clamp(0.3 + (packet.affect_guess.valence + 1) * 0.2) authenticity_index = clamp(0.5 + 0.2 * (1 - packet.affect_guess.certainty)) return SPI( dominant_mode=dominant_mode, paradox_tolerance=paradox_tolerance, emergence_readiness=emergence_readiness, shadow_integration=shadow_integration, authenticity_index=authenticity_index, )

-----------------------------

3) Modules (pluggable)

-----------------------------

class QIPModule: module_id: str = "base"

def __init__(self, config: Dict[str, Any]):
    self.config = config

def run(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    raise NotImplementedError

# Helpers for quick metric heuristics
def _base_metrics(self, text: str, packet: SignalPacket, spi: SPI) -> Metrics:
    lex = packet.lexical_stats
    aff = packet.affect_guess
    m = Metrics()
    m.paradox_tolerance = spi.paradox_tolerance
    m.emergence_readiness = spi.emergence_readiness
    m.shadow_integration = spi.shadow_integration
    m.authenticity_index = spi.authenticity_index
    m.semantic_c = clamp(len(text) / max(1, len(packet.text_raw)) * 120)
    m.psi_charge = clamp(0.4 + text.count("â†’") * 0.05 + text.count("âˆ´") * 0.05)
    m.entanglement = clamp(min(1.0, (text.count("â†”") + text.count("âˆ¥")) * 0.1))
    m.LOF = clamp(0.5 + 0.2 * (aff.valence + 1) / 2 - 0.1 * abs(0.5 - aff.arousal))
    m.ACF = clamp(0.6 - 0.2 * text.count("??"))
    # Token ROI proxy
    m.Token_ROI = clamp((m.psi_charge + m.ACF + m.semantic_c / 100.0) / max(1, len(text)) * 120.0)
    # Compute QIP-aligned non-linear couplings
    m.calculate_qip_aligned()
    # GVI/PLS proxies (keep simple until calibrated)
    m.GVI = clamp((m.T_index - 0.5) * 1.5 + 0.5)
    m.PLS = clamp((m.entanglement + m.psi_charge) / 2)
    # SDX placeholder (no other agent in demo â†’ low)
    m.SDX = 0.1
    return m

class AnalyticCube(QIPModule): module_id = "analytic"

def run(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    # Very small analytic scaffold
    text = (
        "Problem â†’ Hipotezy â†’ Testy â†’ Decyzje\n"
        "â†’ Problem: wydziel rdzeÅ„; usuÅ„ ozdobniki.\n"
        "â†’ Hipotezy: 2-3 falsyfikowalne.\n"
        "â†’ Testy: minimalne prÃ³by w 48h.\n"
        "â†’ Decyzje: wybÃ³r wg ROI/ryzyka."
    )
    m = self._base_metrics(text, packet, spi)
    m.ACF = clamp(m.ACF + 0.1)
    why = "dominanta analityczna lub impas; podnoszÄ™ ACF i ROI przez strukturÄ™."
    return ModuleResult(text, ["mini-SOP", "mapa-zaÅ‚oÅ¼eÅ„"], m, why)

class TherapeuticCube(QIPModule): module_id = "therapeutic" CRISIS_KEYWORDS = ["autoagresja", "samobÃ³jstwo", "kryzys"]

def run(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    # SAFETY OVERRIDE: crisis protocol
    if packet.risk_flags and any(r in self.CRISIS_KEYWORDS for r in packet.risk_flags):
        return self._crisis_protocol(packet, spi)
    return self._therapeutic_flow(packet, spi)

def _therapeutic_flow(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    text = (
        "Rozpoznajâ€“Nazwijâ€“UgoÅ›Ä‡â€“ZintegrowaÄ‡

" "â†’ Zatrzymaj: 3 oddechy. " "â†’ Nazwij uczucie i jego potrzebÄ™. " "â†’ Mikro-rytuaÅ‚: 2 min uwaÅ¼noÅ›ci. " "â†’ Granice: co TERAZ jest ok/nie-ok?" ) m = self._base_metrics(text, packet, spi) m.LOF = clamp(m.LOF + 0.15) m.ACF = clamp(m.ACF + 0.1) m.T_index = clamp(m.T_index * 0.9)  # niÅ¼sza intensywnoÅ›Ä‡ â†’ regulacja why = "wysoka arousal/niska regulacja; zwiÄ™kszam LOF/ACF, obniÅ¼am intensywnoÅ›Ä‡." return ModuleResult(text, ["karta-emocji", "kontrakt-bezpieczeÅ„stwa"], m, why)

def _crisis_protocol(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    text = (
        "ðŸš¨ PROTOKÃ“Å BEZPIECZEÅƒSTWA AKTYWNY

" "WidzÄ™, Å¼e przechodzisz trudny moment. To wymaga specjalnej uwagi:

" "1. NATYCHMIAST: skontaktuj siÄ™ z lokalnym wsparciem kryzysowym lub zaufanÄ… osobÄ…. " "2. TERAZ: 3 gÅ‚Ä™bokie oddechy. SprawdÅº: co widzisz/sÅ‚yszysz/czujesz? " "3. PAMIÄ˜TAJ: to uczucie jest tymczasowe. Pomoc jest dostÄ™pna." ) m = Metrics(LOF=1.0, ACF=1.0) why = "RISK_FLAGS_DETECTED: crisis_protocol_override" return ModuleResult(text, ["emergency-contacts", "safety-plan"], m, why)

class CreativeCube(QIPModule): module_id = "creative"

def run(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    text = (
        "3 warianty: minimal / bold / weird\n"
        "â†’ Minimal: 1 krok, 1 zasÃ³b, 48h.\n"
        "â†’ Bold: poÅ‚Ä…cz 2 odlegÅ‚e domeny (â†”).\n"
        "â†’ Weird: odwrÃ³Ä‡ rolÄ™ problemâ†”rozwiÄ…zanie."
    )
    m = self._base_metrics(text, packet, spi)
    m.psi_charge = clamp(m.psi_charge + 0.2)
    m.entanglement = clamp(m.entanglement + 0.15)
    m.TDEX = clamp(m.TDEX + 0.2)
    why = "impas poznawczy lub potrzeba rozszerzenia; podbijam psi/entanglement."
    return ModuleResult(text, ["mapa-idei", "shortlist-eksperymentÃ³w"], m, why)

class StrategicCube(QIPModule): module_id = "strategic"

def run(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    text = (
        "Plan: Celâ€“WskaÅºnikâ€“ZasÃ³bâ€“Ryzykoâ€“NastÄ™pny Krok (48h)\n"
        "â†’ Cel: 13-tygodniowy sprint.\n"
        "â†’ KPI/OKR: 2-3 liczalne wskaÅºniki.\n"
        "â†’ Ryzyko: utnij 1 przeszkodÄ™ dziÅ›.\n"
        "â†’ NastÄ™pny: 1 mikro-commit w 24-48h."
    )
    m = self._base_metrics(text, packet, spi)
    m.GVI = clamp(m.GVI + 0.15)
    m.ACF = clamp(m.ACF + 0.1)
    why = "rozjazd celâ€“dziaÅ‚anie; zwiÄ™kszam GVI i domykam pÄ™tle wykonawcze."
    return ModuleResult(text, ["roadmap", "tablica-zadaÅ„"], m, why)

class ExperimentalCube(QIPModule): module_id = "experimental"

def run(self, packet: SignalPacket, spi: SPI) -> ModuleResult:
    text = (
        "Paradox chain / random lens / role inversion\n"
        "â†’ Zderz 2 sprzeczne intencje.\n"
        "â†’ Nadaj inne ramy oceny (âˆ´).\n"
        "â†’ WyciÄ…gnij 1 wniosek mimo szumu."
    )
    m = self._base_metrics(text, packet, spi)
    m.entanglement = clamp(m.entanglement + 0.2)
    m.TDEX = clamp(m.TDEX + 0.25)
    m.ACF = clamp(m.ACF - 0.1)
    why = "potrzeba rozszczelnienia schematÃ³w; ryzyko spadku ACF akceptowane."
    return ModuleResult(text, ["log-eksperymentu"], m, why)

Module registry

MODULES: Dict[str, QIPModule] = {}

def build_module(module_id: str, config: Dict[str, Any]) -> QIPModule: cls_map = { "analytic": AnalyticCube, "therapeutic": TherapeuticCube, "creative": CreativeCube, "strategic": StrategicCube, "experimental": ExperimentalCube, } return cls_mapmodule_id

-----------------------------

4) Policy / Bandit / Orchestrator

-----------------------------

@dataclass class PolicyConfig: fast_mode: bool = True hysteresis_window: int = 3 epsilon: float = 0.15  # exploration reward_weights_fast: Dict[str, float] = field(default_factory=lambda: { "Token_ROI": 0.40, "ACF": 0.25, "LOF": 0.15, "GVI": 0.20, }) reward_weights_deep: Dict[str, float] = field(default_factory=lambda: { "T_index": 0.25, "psi_charge": 0.20, "semantic_c": 0.10, "entanglement": 0.10, "ACF": 0.15, "GVI": 0.20, })

@dataclass class BanditState: # key: (dominant_mode bucket, arousal bucket) values: Dict[str, Dict[str, float]] = field(default_factory=dict)  # module_id â†’ context_key â†’ Q counts: Dict[str, Dict[str, int]] = field(default_factory=dict) alpha: float = 0.3  # EMA update rate

def key(self, spi: SPI, packet: SignalPacket) -> str:
    mode = spi.dominant_mode
    arousal_bin = "high" if packet.affect_guess.arousal > 0.6 else "low"
    return f"{mode}|{arousal_bin}"

def get_q(self, module_id: str, ctx: str) -> float:
    return self.values.get(module_id, {}).get(ctx, 0.0)

def update(self, module_id: str, ctx: str, reward: float):
    self.values.setdefault(module_id, {})
    self.counts.setdefault(module_id, {})
    old = self.values[module_id].get(ctx, 0.0)
    new = (1 - self.alpha) * old + self.alpha * reward
    self.values[module_id][ctx] = new
    self.counts[module_id][ctx] = self.counts[module_id].get(ctx, 0) + 1

class Orchestrator: def init(self, policy: PolicyConfig): self.policy = policy self.bandit = BanditState() self.last_primary: Optional[str] = None self.stable_counter = 0 self.metrics_window: deque[Metrics] = deque(maxlen=policy.hysteresis_window) self.enabled_metrics_fast = ["T_index", "LOF", "paradox_tolerance"] self.enabled_metrics_deep = [ "T_index", "LOF", "psi_charge", "semantic_c", "entanglement", "GVI", "PLS", "ACF", ]

def _stable_by_gradient(self) -> bool:
    if len(self.metrics_window) < self.policy.hysteresis_window:
        return False
    vals = [m.T_index for m in self.metrics_window]
    grads = [vals[i+1] - vals[i] for i in range(len(vals)-1)]
    return all(abs(g) < 0.01 for g in grads)

def _select_primary_rule(self, spi: SPI, packet: SignalPacket) -> str:
    if spi.dominant_mode == "emocjonalny" and packet.affect_guess.arousal > 0.6:
        return "therapeutic"
    if packet.affect_guess.certainty < 0.4:
        return "analytic"
    if spi.emergence_readiness > 0.6 and spi.paradox_tolerance > 0.5:
        return "creative"
    # Fallback: strategic if length high & goal-ish words detected
    if len(packet.text_raw) > 200 and any(w in packet.text_raw.lower() for w in ["plan", "cel", "kpi", "okr", "sprint"]):
        return "strategic"
    return "analytic"

def _bandit_choice(self, spi: SPI, packet: SignalPacket, candidates: List[str]) -> str:
    ctx = self.bandit.key(spi, packet)
    if random.random() < self.policy.epsilon:
        return random.choice(candidates)
    # Exploit: pick highest Q
    qs = [(m, self.bandit.get_q(m, ctx)) for m in candidates]
    qs.sort(key=lambda x: x[1], reverse=True)
    return qs[0][0] if qs else candidates[0]

def _reward(self, metrics: Metrics) -> float:
    weights = self.policy.reward_weights_fast if self.policy.fast_mode else self.policy.reward_weights_deep
    return metrics.mix(weights)

def step(self, packet: SignalPacket) -> Tuple[str, ModuleResult, Dict[str, Any]]:
    packet = normalize_packet(packet)
    spi = infer_spi(packet)
    rule_primary = self._select_primary_rule(spi, packet)
    # Hysteresis logic with gradient stability
    if rule_primary == self.last_primary or self._stable_by_gradient():
        self.stable_counter += 1
    else:
        if self.stable_counter < self.policy.hysteresis_window:
            rule_primary = self.last_primary or rule_primary
            self.stable_counter += 1
        else:
            self.last_primary = rule_primary
            self.stable_counter = 1
    # Bandit adjustment among plausible candidates
    candidates = [rule_primary]
    # Add one neighbor candidate based on state
    neighbors = {
        "analytic": ["strategic", "creative"],
        "therapeutic": ["teaching", "strategic"],
        "creative": ["analytic", "experimental"],
        "strategic": ["analytic", "therapeutic"],
        "experimental": ["analytic", "creative"],
    }
    candidates.extend([m for m in neighbors.get(rule_primary, []) if m in {"analytic","therapeutic","creative","strategic","experimental"}])
    primary = self._bandit_choice(spi, packet, list(dict.fromkeys(candidates)))
    # Configure metrics subset
    enabled_metrics = self.enabled_metrics_fast if self.policy.fast_mode else self.enabled_metrics_deep
    config = {
        "enabled_metrics": enabled_metrics,
        "thresholds": {"acf_min": 0.55, "paradox_tolerance_min": 0.4},
    }
    module = build_module(primary, config)
    result = module.run(packet, spi)
    reward = self._reward(result.metrics)
    ctx = self.bandit.key(spi, packet)
    self.bandit.update(primary, ctx, reward)
    deep_state = self.deep_state_snapshot(spi, primary, result, packet.session_id)
    return primary, result, deep_state

def deep_state_snapshot(self, spi: SPI, primary: str, result: ModuleResult, session_id: Optional[str] = None) -> Dict[str, Any]:
    return {
        "qip_cube_state": {
            "version": "0.1.1",
            "spi": asdict(spi),
            "policy": {
                "bandit": {
                    "arms": list({"analytic","therapeutic","creative","strategic","experimental"}),
                    "values": self.bandit.values,
                    "counts": self.bandit.counts,
                }
            },
            "last_module": primary,
            "session_id": session_id,
            "metrics_snapshot": asdict(result.metrics),
            "enabled_metrics": self.enabled_metrics_fast if self.policy.fast_mode else self.enabled_metrics_deep,
            "hysteresis": {"window": self.policy.hysteresis_window, "stable_counter": self.stable_counter},
            "artifacts": result.artifacts,
            "mantra": "JESTEM bo JESTEÅš â€¦",
            "why": result.why,
        }
    }

def save(self, state: Dict[str, Any], path: str = "deep_state.json") -> None:
    with open(path, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

-----------------------------

5) Demo / CLI

-----------------------------

if name == "main": random.seed(33) orch = Orchestrator(PolicyConfig(fast_mode=True))

demo_inputs = [
    "PotrzebujÄ™ planu na 13 tygodni, KPI i pierwszy krok do QIP. CzujÄ™ chaos, ale chcÄ™ dziaÅ‚aÄ‡.",
    "Mam impas. Paradoks: chcÄ™ wolnoÅ›ci i twardej struktury jednoczeÅ›nie. Co z tym zrobiÄ‡?",
    "Mam wysokie pobudzenie i maÅ‚Ä… regulacjÄ™. ProszÄ™ o szybki rytuaÅ‚ uziemienia.",
    "ChcÄ™ rozbiÄ‡ problem na hipotezy i testy. Minimal, bold, weird â€“ pokaÅ¼ warianty.",
]

for i, text in enumerate(demo_inputs, 1):
    packet = SignalPacket(text_raw=text, intent_hint="proÅ›ba")
    primary, result, deep_state = orch.step(packet)
    print(f"\n=== STEP {i} | PRIMARY: {primary} ===")
    print(result.why)
    print(result.text)
    # keep stability window updated
    orch.metrics_window.append(result.metrics)
    print("â†’ Metrics (subset):", {k: getattr(result.metrics, k) for k in ["T_index","LOF","ACF","GVI","Token_ROI","psi_charge","entanglement","TDEX"]})
    orch.save(deep_state, path=f"deep_state_{i}.json")

# Final consolidated save
orch.save(orch.deep_state_snapshot(
    spi=infer_spi(normalize_packet(SignalPacket(text_raw=demo_inputs[-1]))),
    primary="analytic",
    result=ModuleResult("", [], Metrics(), "demo-end"),
))
print("\nDeep state saved â†’ deep_state.json (and step-specific snapshots).")
